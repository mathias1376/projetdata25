Documentation du Modèle de Machine Learning


1. Objectif du Modèle

Dans le cadre de ce projet, nous avons cherché à répondre à la problématique suivante :
"Comment un modèle d'intelligence artificielle peut-il améliorer la précision des prédictions Over/Under sur le nombre d'aces dans un match de tennis afin 
d’optimiser les décisions des parieurs et des opérateurs de paris sportifs ?"

L'objectif est de concevoir un modèle de machine learning permettant de prédire si un match de tennis comportera un nombre élevé ou faible d’aces, 
en se basant sur les données historiques des matchs ATP. Cette information est essentielle pour les acteurs du marché des paris sportifs, 
qui doivent ajuster leurs cotes et stratégies en fonction de prédictions fiables.


2. Démarche et Approche Méthodologique
Notre démarche s'est articulée autour de plusieurs étapes :

a. Compréhension, Exploration et Utilisation des Données
Avant toute modélisation, il était crucial d’analyser la nature des données disponibles. Le dataset utilisé, issu de matchs ATP, contient des informations sur :

- Les joueurs (âge, taille, classement ATP)
- Les matchs (type de surface, durée, gagnant/perdant)
- Les performances au service (nombre d’aces, double fautes, pourcentage de premiers services réussis, vitesse de service etc.)
- Certaines statistiques historiques des joueurs
- Une première analyse exploratoire a permis de :
    * Visualiser la distribution des aces en fonction des surfaces de jeu
    * Identifier les corrélations entre les variables
    * Repérer d'éventuelles incohérences ou valeurs aberrantes

b. Prétraitement et Sélection des Variables
Le prétraitement a consisté à :

Gérer les valeurs manquantes : suppression ou imputation selon le cas.
Encodage des variables catégorielles : transformation des types de surfaces et noms de joueurs en variables numériques.
Standardisation des variables numériques : utilisation de StandardScaler pour homogénéiser les valeurs.
Création d’une variable cible : transformation du nombre d’aces en une variable binaire indiquant si le nombre dépasse un certain seuil (Over/Under).
Un sélectionneur de variables basé sur LASSO a ensuite été utilisé pour identifier les caractéristiques les plus influentes.

c. Modélisation et Expérimentations
Différents modèles ont été testés afin d’optimiser la précision des prédictions :

Nous avons choisi comme modèle de base le modèle Random Forest pour les avantages suivants :
- Bonne gestion des données hétérogènes
- Identification des variables les plus influentes

Les résultats obtenus sont intéressants mais pouvant être améliorés puiqu'ils manquent de précision avec une MAE trop grand.

Voici les autres modèles explorés :
- Régression logistique. C'est rapide, mais trop simpliste pour capter la complexité des données.
- Support Vector Machine (SVM). Assez efficace mais très lent sur de grandes bases.
- XGBoost. On obtient de bonnes performances après tuning des hyperparamètres mais les résultats sont sensiblement les mêmes que le Random Forest.
- Réseaux de neurones : testé via un MLP, mais ce modèle nécessitait plus de données et un réglage peut-être plus fin.
- Le RandomForestClassifier a finalement été retenu comme modèle principal en raison de son bon équilibre entre performance et interprétabilité.

d. Évaluation et Analyse des Résultats

Les performances du modèle ont été mesurées à l'aide de :
Accuracy Score pour mesurer la proportion de prédictions correctes.
F1 Score qui permet d'évaluer la précision et le rappel simultanément.
Matrice de confusion qui permet l'identification des erreurs courantes dans les classifications.

Les meilleurs résultats que nous avons obtenus ont été récupérés avec le modème Random Forest, en utilisant plus de variables que la première analyse effectuées
avec ce type de machine learning. Les variables sont le gagnant du match, le type de surface, le type de best of, le nombre de fois où le gagnant a servi 
et le pourcentage de première balle passée par le vainqueur.
Avec cela, notre Random Forest à pu identifier les matchs avec un nombre élevé d’aces même s'il a eu des difficultés à prédire les matchs où les 
joueurs ont des styles plus variés ou jouent sur des surfaces spécifiques.
La MAE et la RMSE sont plus faibles que lors du premier essai avec Random Forest.

Nous avons identifié des axes d'amélioration :
* Prendre en compte l’historique des performances des joueurs.
* Explorer des méthodes de deep learning pour mieux capturer les tendances complexes.
* Intégrer des données supplémentaires (conditions météorologiques, type de tournoi, altitude).


3. Documentation Technique : Pipeline de Données et Modèle

a. Pipeline de Données
Le traitement des données suit un pipeline structuré.
    - Chargement et exploration des données
    - Lecture du fichier atp_matches_2023.csv
    - Analyse statistique et détection des valeurs aberrantes
       Prétraitement
    - Nettoyage des données
    - Transformation des variables catégorielles
    - Standardisation des variables numériques
    - Sélection des variables
    - Analyse de l’importance des features avec LASSO et Random Forest
    - Séparation des données
    - Division en jeu d'entraînement (80%) et jeu de test (20%)
    - Modélisation
    - Entraînement du modèle RandomForestClassifier
    - Comparaison avec d'autres modèles pour validation
    - Évaluation
    - Calcul des métriques de performance
    - Analyse des résultats et visualisation

b. Documentation du Modèle
Modèle principal : Random Forest
Le modèle utilisé est un Random Forest Classifier, qui repose sur la combinaison de plusieurs arbres de décision pour améliorer la robustesse des prédictions.

Hyperparamètres utilisés :

n_estimators = 100
max_depth = None
min_samples_split = 2
min_samples_leaf = 1
random_state = 42
Ce choix a plusieurs avantages puisque'il réduit le risque de sur-apprentissage grâce à la méthode d’ensemble.
Il identifie les variables les plus influentes et est facile à interpréter et ajuster.

Résultats du modèle :
Feature Importance : Les variables les plus impactantes sont la surface de jeu, le classement ATP et la taille des joueurs.
Les performances générales sont bonnes, mais une amélioration est possible avec des modèles plus avancés.


4. Pistes Explorées et Tests Non Conclusifs
Tout au long du projet, nous avons tenté plusieurs approches mais ces dernieres n'ont pas abouti aux résultats escomptés.

Nous avons mis un place un test d’une régression linéaire pour prédire directement le nombre d’aces.
Les résultats sont médiocres, car les distributions des aces sont très dispersées.

Nous avons essayé d'intoduire l'historique des 10 derniers matchs.
Cependant, il y a peu de gain en précision avec ceci, probablement en raison d’un manque de données complètes.

Nous avons test un modèle basé uniquement sur les caractéristiques des joueurs mais les performances sont mauvaises, car les conditions de jeu 
influencent fortement le nombre d’aces.


5. Conclusion et Perspectives

Le modèle développé offre une première approche assez viable pour la prédiction Over/Under du nombre d’aces dans un match de tennis. 
Cependant, plusieurs axes d’amélioration restent envisageables et même nécessaires :

D'abord l'enrichissement des données avec par exemple l'ajout des saisons précédentes, conditions météo, type de tournoi.
De même, l'optimisation des hyperparamètres pour des tests plus approfondis des paramètres via GridSearchCV.
Ensuite, une exploration d’algorithmes plus avancés comme LSTM pour capturer l’évolution temporelle des performances des joueurs.

Ce projet démontre l’intérêt du machine learning pour affiner les stratégies des parieurs et ouvre des perspectives vers des modèles plus complexes.
Les bookmakers ont tout intérêt à s'intéresser à ce type de technologie nouvelle. Le gain de précision dans les prédictions est considérable.
